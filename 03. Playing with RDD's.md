# Exploring Spark Core - RDD's

## Introductions

> RDD (Resilient Distributed Dataset) it is a fundamental data structure of Apache spark

* It is all about creating RDD's
* All the methods to create RDD's is present inside SparkContext (sc)

## Partition

> A partition in spark is a logical division of data stored in the node

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdnAjG3j5jL8U0iD_rnMc_bmiKy_FoVG1E7fPIFxAMnyyDmEd0sbI8CMjuGAE3plCqeHr1b5-SctKWXZWF7I-8riSGuWDO0MYerrt5Tzypa4GbkUtQRaPDa40lUDtJWnpJh9cWGQvlJNdz1b_-S3WIa1Rw?key=uvmlVet7-pBAx-jz0PuzLA)



## RDD Creation 

There are two ways to create an RDD

1. Create an RDD from Collection

   ```python
   L = list(range(1,101))
   numbers_rdd = sc.parallelize(L)
   print(type(numbers_rdd))
   ```

   

2. Create an RDD from External Source

   ```
   employee_rdd = sc.textFile("c:/employee.dat)
   print(type(employee_rdd)
   ```

   

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfQisoaMumuAV1VtKSy56sW8uXSvvwOV07aeQeLM6hse6_IFk82YtN5V8eyJkoaH-9UGyG2p0C2mWPEA-xP5hYwENjiFDFBaCHiBG5XfsW3g06C5NCOQLW0V-quUnx6eRaubTzTpd5OZbehT6ErOTg8Iwg?key=uvmlVet7-pBAx-jz0PuzLA)



## Operations

Once an RDD is created we can perform two types of operations

1. Transformation
2. Actions

### Transformation

* Transformation creates a new RDD from existing RDD.

  ![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXdMO06V8H0PSWgP-a3zeOqaBF8mLGGNccz5diKFK3kiz5y8HmAcPK1a5cVHEmDIfgvYR3gkIQu--wgiVs59VcUI33w00xaSwDCgXfaR3lq_TdGGOyHheY_iMHUfD1a7BsQW1VgrCkCD6S8xC-aQRPwn18id?key=uvmlVet7-pBAx-jz0PuzLA)

* E.g

  * map, filter, sample, partitionByKey

### Actions

* The actual computation takes place only when you execute an action