# Exploring Spark SQL

> Spark SQL is one of the module in the Spark Ecosystem, to query and analyze structured and semi-structured data.

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXciUOPtET1s3nsP_jHbNbrKGbcwyfJC7TUc4Dk1dvIvChATEXSlch18vgFO9046-nQcIeQqpBvtVJkpFX7hGSAYUSXE49fbO33BGDcrBEU46YIRAUkI6UWVoKyxafHWmgXWnND1GOznwdbtRMv0Uqo-O5o?key=tHXUAiwd9ksVr1IakYoP6A)

* It provides higher level of abstraction than the Spark core API.
* We can interact with Spark SQL : SQL, DataFrame API, Dataset API (Not supported with Python)



In any spark application we perform three steps

1. Load the data into Spark Data Structure
2. Process the data
3. Write the results to different location

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXeSAJYgLOS_9YmjH23pfcmKqTtkCJr-nlEard5JAk1ivmXTsKT26g5uaGVn_OoMiNgqNcGutjMi8qOOhpHc5oyxXrbotoPajBtrBtYVT-EHRb_i8T4-3IPKEk_Nv0gcaZUUvtxocbU6K7DUe6pqRGCT6auU?key=Ho-EZjExtA4N0KIuSunUoA)

**What is DataFrame**

> DF is an in-memory table

* Conceptually DF is like an table in RDBS







All the methods to create DF is present inside which object

DataFrameReader

```
dfr = spark.read
```

DataFrameReader

​	.json

​	.csv

​	.parquet

​	.orc

​	.parquet



**Methods Present inside DataFrame**

DataFrame

​			. show()

​			.display()

​			.printSchema()

​		

```python
employee_df = spark.read.csv(path="",
                            header=True,
                            schema=CUSTOM_SCHEMA,
                            sep="|")


employee_df.select("id","name").display()

```

