# Apache Spark

> Apache Spark is an **In-Memory** cluster computing framework designed for big data workloads

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXc3jyVhRCwQ8yPL8-dB4SqZnqfudm0V-xn5qo3I5g7MLfQ_vD9XK-qoABNXiVP_7CHAUP7G_mtoI_BOlmjz8KnmO9xqQRekQrNB_V4H5bdB-7tvDLlANDt-FPwH-RqQjGAT5enDLxFXKkLlpYrM4a1Mvs6B?key=KG4XycolQz2vWFq2bNIfEQ)

**Application of Apache Spark**

1. Data Integration and ETL
2. High Performance Batch Computation
3. Machine Learning Analytics
4. Real-time stream processing

**Important Points**

* The main feature of Spark, is it **in-memory** 
* Spark is natively written using **Scala** (JVM based language)



## What is PySpark

> PySpark is the Python API for Apache Spark.



![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXciR4ZsvTPtS05yjRUatMaBiWAECVsI7ymj3uzwOKcgkViyBFglL5sFRkEqeFqKFz1nLGjZQPNJqnTuACLUxQ25NYMd6CUt4JwhS9PU-acyeraunRgxkgjC7V5aRs9xmbvOcG-oRG7zeWbmu2TbQDwRx5Y?key=uvmlVet7-pBAx-jz0PuzLA)

* The PySpark communicates with Spark using **Py4J**
* 

## Eco-system

Spark is a <u>distributed computing framework,</u> which comes with bunch of libraries

![img](https://lh7-rt.googleusercontent.com/docsz/AD_4nXciUOPtET1s3nsP_jHbNbrKGbcwyfJC7TUc4Dk1dvIvChATEXSlch18vgFO9046-nQcIeQqpBvtVJkpFX7hGSAYUSXE49fbO33BGDcrBEU46YIRAUkI6UWVoKyxafHWmgXWnND1GOznwdbtRMv0Uqo-O5o?key=tHXUAiwd9ksVr1IakYoP6A)



## Spark Interactive Shell

1. Spark Shell (scala)

   ```
   $> spark-shell
   ```

   

2. PySpark Shell (Python)

   ```
   $> pyspark
   ```

   











